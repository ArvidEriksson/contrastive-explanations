{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import colors\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch import nn\n",
    "from dataset import CUB\n",
    "from utils import *\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "# Change this to your own path for the downloaded and unzipped CUB dataset. Also requires model fine-tuned on CUB. Use train.py for this.\n",
    "data_root = '..'\n",
    "model_name = 'vgg'\n",
    "image_size = 224\n",
    "threshold = 0.1\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_name == 'vgg':\n",
    "    model = torchvision.models.vgg16_bn(pretrained = False).to(device)\n",
    "elif model_name == 'alexnet':\n",
    "    model = torchvision.models.alexnet(pretrained = False).to(device)\n",
    "model.classifier[6] = nn.Linear(4096, 200).to(device)\n",
    "model.load_state_dict(torch.load(f'model/{model_name}_CUB.pth'))\n",
    "\n",
    "model.eval()\n",
    "testset = CUB(data_root, normalization=True, train_test='test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find samples where the third class prediction has a high relative probability\n",
    "samples = get_samples(testset,model,threshold,max_no_samples=50,no_targets=3)\n",
    "os.makedirs(\"./comparison_max_mean\", exist_ok=True)\n",
    "\n",
    "for (n, y1, y2, y3) in tqdm(samples):\n",
    "    image = testset[n][0].view(1,3,224,224).to(device)\n",
    "    label = testset[n][1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prob = torch.softmax(model(image),dim=1)[0]\n",
    "        argsort=prob.argsort()\n",
    "        t1 = argsort[-1]\n",
    "        t2 = argsort[-2]\n",
    "        t3 = argsort[-3]\n",
    "    \n",
    "    folder_path = \"./comparison_max_mean/%s\" % (str(n) + \"_true_\" + str(label))\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    # Save input image\n",
    "    plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "    plt.axis('off')\n",
    "    plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "    plt.savefig(folder_path + \"/input.png\", bbox_inches='tight', pad_inches=0)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Showing image:\\t%d\" %(n))\n",
    "    print(\"True label:\\t%d\" %(label))\n",
    "    print(\"Top class:\\t%d,\\tconfidence = %.3f\\nSecond class:\\t%d,\\tconfidence = %.3f\\nThird class:\\t%d,\\tconfidence = %.3f\"\\\n",
    "              %(t1, prob[t1],t2, prob[t2],t3, prob[t3]))\n",
    "        \n",
    "    for mode in ['GC']:      \n",
    "        for t, t_string in [(t1, \"t1\"), (t2, \"t2\"), (t3, \"t3\")]:\n",
    "            gradcam = get_saliency(model, image, t, mode=mode, explanation='original')\n",
    "            gradcam_weighted = get_saliency(model, image, t, mode=mode, explanation='weighted')\n",
    "            gradcam_mean = get_saliency(model, image, t, mode=mode, explanation='mean')\n",
    "            gradcam_max = get_saliency(model, image, t, mode=mode, explanation='max')\n",
    "            # For displaying differences between original and mean, as they are very hard to spot\n",
    "            # diffcam = (gradcam - gradcam_mean).abs()\n",
    "                        \n",
    "            print(\"Original\")\n",
    "            plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "            plt.imshow(gradcam.detach().cpu().squeeze().numpy(), cmap='bwr', alpha=0.5, norm=colors.CenteredNorm(0))\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "            path = (\"%s/original_%s_%s_%d_%.3f.png\" % (folder_path, mode, t_string, t, prob[t]))\n",
    "            plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Weighted\")\n",
    "            plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "            plt.imshow(gradcam_weighted.detach().cpu().squeeze().numpy(), cmap='bwr', alpha=0.5, norm=colors.CenteredNorm(0))\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "            path = (\"%s/weighted_%s_%s_%d_%.3f.png\" % (folder_path, mode, t_string, t, prob[t]))\n",
    "            plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Mean\")\n",
    "            plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "            plt.imshow(gradcam_mean.detach().cpu().squeeze().numpy(), cmap='bwr', alpha=0.5, norm=colors.CenteredNorm(0))\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "            path = (\"%s/mean_%s_%s_%d_%.3f.png\" % (folder_path, mode, t_string, t, prob[t]))\n",
    "            plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Max\")\n",
    "            plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "            plt.imshow(gradcam_max.detach().cpu().squeeze().numpy(), cmap='bwr', alpha=0.5, norm=colors.CenteredNorm(0))\n",
    "            plt.axis('off')\n",
    "            plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "            path = (\"%s/max_%s_%s_%d_%.3f.png\" % (folder_path, mode, t_string, t, prob[t]))\n",
    "            plt.savefig(path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "            \n",
    "            # print(\"Difference between original and mean (normalized)\")\n",
    "            # plt.imshow(denorm(image).detach().cpu().numpy().squeeze().transpose((1,2,0)))\n",
    "            # plt.imshow(diffcam.detach().cpu().squeeze().numpy(), cmap='jet', alpha=0.5, norm=colors.CenteredNorm(0))\n",
    "            # plt.axis('off')\n",
    "            # plt.subplots_adjust(top = 1, bottom = 0, right = 1, left = 0, hspace = 0, wspace = 0)\n",
    "            # plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m111",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m111"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
